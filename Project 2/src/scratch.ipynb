{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise  import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(X1, X2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute linear kernel between two set of feature vectors.\n",
    "    The constant 1 is not appended to the x's.\n",
    "\n",
    "    X1: n x m1 matrix, each of the m1 column is an n-dim feature vector.\n",
    "    X2: n x m2 matrix, each of the m2 column is an n-dim feature vector.\n",
    "    \n",
    "    Note that m1 may not equal m2\n",
    "\n",
    "    :return: if both m1 and m2 are 1, return linear kernel on the two vectors; else return a m1 x m2 kernel matrix K,\n",
    "            where K(i,j)=linear kernel evaluated on column i from X1 and column j from X2.\n",
    "    \"\"\"\n",
    "    #########################################\n",
    "    shape_1 = X1.shape\n",
    "    shape_2 = X2.shape\n",
    "    K = np.zeros((shape_1[0], shape_2[1]))\n",
    "    if shape_1[1] == 1 and shape_2[1] == 1:\n",
    "        \n",
    "        return np.dot(X1.T, X2)\n",
    "\n",
    "    else:\n",
    "        K = np.zeros((shape_1[0], shape_2[1]))\n",
    "        for i in range(shape_1[0]):\n",
    "            for j in range(shape_2[1]):\n",
    "                    K[i,j] = np.dot(X1[:,i], X2[:,j])\n",
    "        return K\n",
    "    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.,  5., 17.],\n",
       "       [22., 10., 34.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = np.array([[1, 2], [2, 4]]).T\n",
    "X2 = np.array([[3, 4], [1, 2], [5, 6]]).T\n",
    "\n",
    "linear_kernel(X1,X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_kernel(X1, X2, sigma=1):\n",
    "    \"\"\"\n",
    "    Compute Gaussian kernel between two set of feature vectors.\n",
    "    \n",
    "    The constant 1 is not appended to the x's.\n",
    "    \n",
    "    For your convenience, please use euclidean_distances.\n",
    "\n",
    "    X1: n x m1 matrix, each of the m1 column is an n-dim feature vector.\n",
    "    X2: n x m2 matrix, each of the m2 column is an n-dim feature vector.\n",
    "    sigma: Gaussian variance (called bandwidth)\n",
    "\n",
    "    Note that m1 may not equal m2\n",
    "\n",
    "    :return: if both m1 and m2 are 1, return Gaussian kernel on the two vectors; else return a m1 x m2 kernel matrix K,\n",
    "            where K(i,j)=Gaussian kernel evaluated on column i from X1 and column j from X2\n",
    "\n",
    "    \"\"\"\n",
    "    #########################################\n",
    "    shape_1 = X1.shape\n",
    "    shape_2 = X2.shape\n",
    "\n",
    "    if shape_1[1] == 1 and shape_2[1] == 1:\n",
    "        return np.array([[np.exp( -(np.linalg.norm(X1[0,:] - X2[0,:])**2) )/(2*sigma**2)]])\n",
    "\n",
    "        #Kernel = np.trace(K)\n",
    "\n",
    "    else:\n",
    "        K = np.zeros((shape_1[0], shape_2[1]))\n",
    "        for i in range(shape_1[0]):\n",
    "            for j in range(shape_2[1]):\n",
    "                    K[i,j] = np.exp(-(euclidean_distances(np.array([X1[:,i]]),np.array([X2[:,j]]))**2)/(2*sigma**2))\n",
    "        return K\n",
    "    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85214379, 1.        , 0.52729242],\n",
       "       [0.98019867, 0.90483742, 0.77105159]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = np.array([[1, 2], [2, 4]]).T\n",
    "X2 = np.array([[3, 4], [1, 2], [5, 6]]).T\n",
    "#X1 = np.array([[1, 2]]).T\n",
    "#X2 = np.array([[3, 4]]).T\n",
    "Gaussian_kernel(X1, X2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(z, y):\n",
    "    \"\"\"\n",
    "    Compute the hinge loss on a set of training examples\n",
    "    z: 1 x m vector, each entry is <w, x> + b (may be calculated using a kernel function)\n",
    "    y: 1 x m label vector. Each entry is -1 or 1\n",
    "    :return: 1 x m hinge losses over the m examples\n",
    "    \"\"\"\n",
    "    #########################################\n",
    "    shape_1 = max(z.shape)\n",
    "    K = np.zeros((shape_1))\n",
    "    for i in range(shape_1):\n",
    "        K[i] = max(0, 1 - np.dot(y[:,i],z[i]))\n",
    "    return K\n",
    "    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 6.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 2], [2, 4]]).T\n",
    "y = np.array([[1, -1]])\n",
    "w = np.array([1, 1])\n",
    "b = -1\n",
    "\n",
    "z = np.dot(w, X) + b\n",
    "\n",
    "hinge_loss(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 99 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\MFE\\MFE Sem 3\\CSE 426\\CSE_426\\Project 2\\src\\scratch.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1010sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39mdot(y[:,i],z[i])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 99 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "np.dot(y[:,i],z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2])"
      ]
     },
     "execution_count": 1437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - np.dot(y[:,0],z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6])"
      ]
     },
     "execution_count": 1434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6])"
      ]
     },
     "execution_count": 1433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(0, 1 - np.dot(y,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 0.])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_loss(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probelm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_objective_function(alpha, train_y, train_X, kernel_function, sigma):\n",
    "      \"\"\"\n",
    "      Compute the dual objective function value.\n",
    "\n",
    "      alpha: 1 x m learned Lagrangian multipliers (the dual variables).\n",
    "      train_y: 1 x m labels (-1 or 1) of training data.\n",
    "      train_X: n x m training feature matrix. n: number of features; m: number training examples.\n",
    "      kernel_function: a kernel function implemented in problem1 (Python treats functions as objects).\n",
    "      sigma: need to be provided when Gaussian kernel is used.\n",
    "      :return: a scalar representing the dual objective function value at alpha\n",
    "      Hint: refer to the objective function of Eq. (47).\n",
    "            You can try to call kernel_function.__name__ to figure out which kernel are used.\n",
    "      \"\"\"\n",
    "      #########################################\n",
    "      if kernel_function.__name__ == 'linear_kernel':\n",
    "            Kernels = linear_kernel(train_X, train_X)\n",
    "            K = np.zeros((Kernels.shape[0], Kernels.shape[0]))\n",
    "\n",
    "            for i in range(Kernels.shape[0]):\n",
    "                  for j in range(Kernels.shape[1]):\n",
    "                        K[i,j] = alpha[0][i]*alpha[0][j]*train_y[0][i]*train_y[0][j]*Kernels[i][j]\n",
    "            \n",
    "            return (np.sum(alpha) - 0.5*np.sum(K))\n",
    "\n",
    "      elif kernel_function.__name__ == 'Gaussian_kernel':\n",
    "            Kernels = Gaussian_kernel(train_X, train_X)\n",
    "            K = np.zeros((Kernels.shape[0], Kernels.shape[0]))\n",
    "\n",
    "            for i in range(Kernels.shape[0]):\n",
    "                  for j in range(Kernels.shape[1]):\n",
    "                        K[i,j] = alpha[0][i]*alpha[0][j]*train_y[0][i]*train_y[0][j]*Kernels[i][j]\n",
    "            \n",
    "            return (np.sum(alpha) - 0.5*np.sum(K))\n",
    "\n",
    "\n",
    "    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primal_objective_function(alpha, train_y, train_X, b, C, kernel_function, sigma):\n",
    "    \"\"\"\n",
    "    Compute the primal objective function value.\n",
    "    When with linear kernel:\n",
    "        The primal parameter w is recovered from the dual variable alpha.\n",
    "    When with Gaussian kernel:\n",
    "        Can't recover the primal parameter and kernel trick needs to be used to compute the primal objective function.\n",
    "\n",
    "    alpha: 1 x m learned Lagrangian multipliers (the dual variables).\n",
    "    train_y: 1 x m labels (-1 or 1) of training data.\n",
    "    train_X: n x m training feature matrix.\n",
    "    b: bias term\n",
    "    C: regularization parameter of soft-SVM\n",
    "    kernel_function: a kernel function implemented in problem1 (Python treats functions as objects).\n",
    "    sigma: need to be provided when Gaussian kernel is used.\n",
    "\n",
    "    :return: a scalar representing the primal objective function value at alpha\n",
    "    Hint: you need to use kernel trick when come to Gaussian kernel. Refer to the derivation of the dual objective function Eq. (47) to check how to find\n",
    "            1/2 ||w||^2 and the decision_function with kernel trick.\n",
    "    \"\"\"\n",
    "    #########################################\n",
    "    if kernel_function.__name__ == 'linear_kernel':\n",
    "        #k = linear_kernel(train_X, train_X)\n",
    "        w = np.array([np.sum(alpha[0][i]*train_y[0][i]*train_X[:,i]) for i in range(train_X.shape[0])])\n",
    "\n",
    "        z = np.dot(w, train_X)+b\n",
    "        loss = hinge_loss(z, train_y)\n",
    "\n",
    "        return (0.5*np.linalg.norm(w)**2 + C*np.sum(loss))\n",
    "\n",
    "    elif kernel_function.__name__ == 'Gaussian_kernel':\n",
    "        K = Gaussian_kernel(train_X, train_X, sigma)\n",
    "        Gram = np.zeros((K.shape[0], K.shape[0]))\n",
    "        #wTx = [[]]\n",
    "        for i in range(K.shape[0]):\n",
    "                for j in range(K.shape[1]):\n",
    "                    Gram[i,j] = alpha[0][i]*alpha[0][j]*train_y[0][i]*train_y[0][j]*K[i][j]\n",
    "\n",
    "        uno = np.multiply(alpha, train_y)\n",
    "        Gram = np.dot(K.T, K)\n",
    "        uno_gram = np.dot(uno, Gram)\n",
    "        done = np.dot(uno_gram, uno.T)\n",
    "\n",
    "        front = 0.5*done\n",
    "        z = sum(alpha*K)+b\n",
    "        loss = hinge_loss(z,train_y)\n",
    "        return (front + C*np.sum(loss))\n",
    "    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 1308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array([[1, 1], [-1, -1]]).T\n",
    "train_y = np.array([[1, -1]])\n",
    "alpha = np.array([[1, 1]])\n",
    "b = -1\n",
    "C = 10\n",
    "sigma = None\n",
    "\n",
    "w = np.array([np.sum(alpha[0][i]*train_y[0][i]*train_X[:,i]) for i in range(train_y.shape[1])])\n",
    "\n",
    "z = np.dot(w, train_X)+b\n",
    "loss = hinge_loss(z, train_y)\n",
    "\n",
    "(0.5*np.dot(w,w) + C*np.sum(loss))\n",
    "#primal_objective_function(alpha, train_y, train_X, b, C, linear_kernel, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 1319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array([[1, 1], [-2, -2]]).T\n",
    "train_y = np.array([[1, 1]])\n",
    "alpha = np.array([[1, 1]])\n",
    "b = -1\n",
    "C = 10\n",
    "\n",
    "sigma = None\n",
    "\n",
    "w = np.array([np.sum(alpha[0][i]*train_y[0][i]*train_X[:,i]) for i in range(train_X.shape[0])])\n",
    "\n",
    "z = np.dot(w, train_X)+b\n",
    "loss = hinge_loss(z, train_y)\n",
    "\n",
    "(0.5*np.linalg.norm(w)**2 + C*np.sum(loss))\n",
    "#primal_objective_function(alpha, train_y, train_X, b, C, linear_kernel, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from problem2 import *\n",
    "train_X = np.array([[1, 1], [-1, -1]]).T\n",
    "train_y = np.array([[1, -1]])\n",
    "alpha = np.array([[1, 1]])\n",
    "b = -1\n",
    "C = 10\n",
    "\n",
    "sigma = 1\n",
    "\n",
    "K = Gaussian_kernel(train_X, train_X)\n",
    "\n",
    "# ||w||^2 \n",
    "front = np.dot(np.dot(np.multiply(alpha, train_y), K), np.multiply(alpha, train_y).T) \n",
    "# y(wTx+b)\n",
    "z = sum(np.dot(np.multiply(alpha,train_y),K))+b\n",
    "# loss\n",
    "loss = hinge_loss(z, train_y)\n",
    "\n",
    "0.5*front + C*np.sum(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13533528, 0.13533528],\n",
       "       [0.13533528, 0.13533528]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.16484075]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha*train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01831564, 0.        ])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98168436, -0.98168436])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.01831564],\n",
       "       [ 0.01831564, -1.        ]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha*train_y*K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01831564, -2.01831564])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98168436, 1.01831564])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.96336872]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98168436]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01831564, 0.01831564]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.01831564],\n",
       "       [0.01831564, 1.        ]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(alpha, K)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.96336872]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.18315634]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11.1648407-front_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98168436, 0.98168436])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.01831564, -1.01831564])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.018315638888734"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41.]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array([[1, 1], [-2, -2]]).T\n",
    "train_y = np.array([[1, 1]])\n",
    "alpha = np.array([[1, 1]])\n",
    "b = -1\n",
    "C = 10\n",
    "\n",
    "sigma = 1\n",
    "K = linear_kernel(train_X, train_X)\n",
    "\n",
    "# ||w||^2 \n",
    "front = np.dot(np.dot(np.multiply(alpha, train_y), K), np.multiply(alpha, train_y).T) \n",
    "# y(wTx+b)\n",
    "z = sum(np.dot(np.multiply(alpha,train_y),K))+b\n",
    "# loss\n",
    "loss = hinge_loss(z, train_y)\n",
    "\n",
    "0.5*front + C*np.sum(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01831563]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(11.1648407 - front_1)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00024682]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z = sum(alpha*K) + b\n",
    "\n",
    "z = front \n",
    "loss = hinge_loss(z,train_y)\n",
    "front_1 + C*np.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00012341, 1.00012341])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.23409804e-04],\n",
       "       [1.23409804e-04, 1.00000000e+00]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.01831564],\n",
       "       [0.01831564, 1.        ]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.67399852, 10.67399852])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(11.1648407 - front_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9633687222225316"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.01831564],\n",
       "       [-0.01831564,  1.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uno = np.multiply(alpha, train_y)\n",
    "Gram = np.dot(K.T, K)\n",
    "uno_gram = np.dot(uno, Gram)\n",
    "done = np.dot(uno_gram, uno.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.99777864]])"
      ]
     },
     "execution_count": 1579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array([[1, 1], [-2, -2]]).T\n",
    "train_y = np.array([[1, 1]])\n",
    "alpha = np.array([[1, 1]])\n",
    "b = -1\n",
    "C = 10\n",
    "sigma = 1\n",
    "K = Gaussian_kernel(train_X, train_X, sigma)\n",
    "Gram = np.zeros((K.shape[0], K.shape[0]))\n",
    "#wTx = [[]]\n",
    "for i in range(K.shape[0]):\n",
    "        for j in range(K.shape[1]):\n",
    "            Gram[i,j] = alpha[0][i]*alpha[0][j]*train_y[0][i]*train_y[0][j]*K[i][j]\n",
    "\n",
    "\n",
    "\n",
    "uno = np.multiply(alpha, train_y)\n",
    "Gram = np.dot(K.T, K)\n",
    "uno_gram = np.dot(uno, Gram)\n",
    "done = np.dot(uno_gram, uno.T)\n",
    "\n",
    "front = 0.5*done\n",
    "z = sum(alpha*K)+b\n",
    "loss = hinge_loss(z,train_y)\n",
    "front + C*np.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_function(alpha, train_y, train_X, b, kernel_function, sigma, test_X):\n",
    "    \"\"\"\n",
    "    Compute the linear function <w, x> + b on examples in test_X, using the current SVM.\n",
    "\n",
    "    alpha: 1 x m learned Lagrangian multipliers (the dual variables).\n",
    "    train_y: 1 x m labels (-1 or 1) of training data.\n",
    "    train_X: n x m training feature matrix.\n",
    "    test_X: n x m2 test feature matrix.\n",
    "    b: scalar, the bias term in SVM <w, x> + b.\n",
    "    kernel_function: a kernel function implemented in problem1 (Python treats functions as objects).\n",
    "    sigma: need to be provided when Gaussian kernel is used.\n",
    "\n",
    "    :return: 1 x m2 vector <w, x> + b\n",
    "    \"\"\"\n",
    "    #########################################\n",
    "    if kernel_function.__name__ == 'linear_kernel':\n",
    "        return np.dot(np.multiply(alpha,y), linear_kernel(test_X, train_X))+b\n",
    "    elif kernel_function.__name__ == 'Gaussian_kernel':\n",
    "        return np.dot(np.multiply(alpha,y), Gaussian_kernel(test_X, train_X, sigma))+b\n",
    "    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.98168436, 3.01831564]])"
      ]
     },
     "execution_count": 1599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array([[1, 1], [-1, -1]]).T\n",
    "train_y = np.array([[1, -1]])\n",
    "test_X = np.array([[1, 1], [-1, -1]]).T\n",
    "alpha = np.array([[1, 1]])\n",
    "b = 4\n",
    "\n",
    "sigma = None\n",
    "sigma = 1\n",
    "\n",
    "decision_function(alpha, train_y, train_X, b, linear_kernel, sigma, test_X)\n",
    "decision_function(alpha, train_y, train_X, b, Gaussian_kernel, sigma, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8., 0.]])"
      ]
     },
     "execution_count": 1594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_function(alpha, train_y, train_X, b, Gaussian_kernel, sigma, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem1 import *\n",
    "from problem2 import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "class SVMModel():\n",
    "    \"\"\"\n",
    "    The class containing information about the SVM model, including parameters, data, and hyperparameters.\n",
    "\n",
    "    DONT CHANGE THIS DEFINITION!\n",
    "    \"\"\"\n",
    "    def __init__(self, train_X, train_y, C, kernel_function, sigma=1):\n",
    "        \"\"\"\n",
    "            train_X: n x m training feature matrix. n: number of features; m: number training examples.\n",
    "            train_y: 1 x m labels (-1 or 1) of training data.\n",
    "            C: a positive scalar\n",
    "            kernel_function: a kernel function implemented in problem1 (Python treats functions as objects).\n",
    "            sigma: need to be provided when Gaussian kernel is used.\n",
    "        \"\"\"\n",
    "        # data\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "        self.n, self.m = train_X.shape\n",
    "\n",
    "        # hyper-parameters\n",
    "        self.C = C\n",
    "        self.kernel_func = kernel_function\n",
    "        self.sigma = sigma\n",
    "\n",
    "        # parameters\n",
    "        self.alpha = np.zeros((1, self.m))\n",
    "        self.b = 0\n",
    "\n",
    "def train(model, max_iters = 10, record_every = 1, max_passes = 1, tol=1e-6):\n",
    "    \"\"\"\n",
    "    SMO training of SVM\n",
    "    model: an SVMModel\n",
    "    max_iters: how many iterations of optimization\n",
    "    record_every: record intermediate dual and primal objective values and models every record_every iterations\n",
    "    max_passes: each iteration can have maximally max_passes without change any alpha, used in the SMO alpha selection.\n",
    "    tol: numerical tolerance (exact equality of two floating numbers may be impossible).\n",
    "    :return: 4 lists (of iteration numbers, dual objectives, primal objectives, and models)\n",
    "    Hint: refer to subsection 3.5 \"SMO\" in notes.\n",
    "    \"\"\"\n",
    "    #########################################\n",
    "    ## INSERT YOUR CODE HERE\n",
    "    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array([[1, 1], [-1, -1]]).T\n",
    "train_y = np.array([[1, -1]])\n",
    "C = 10\n",
    "sigma = 1\n",
    "tol = 1e-6\n",
    "\n",
    "# Instantiate model\n",
    "model = SVMModel(train_X, train_y, C, linear_kernel, sigma)\n",
    "max_iters = 10\n",
    "record_every = 1\n",
    "\n",
    "\n",
    "# Creating the lists\n",
    "iter_num = []\n",
    "duals = []\n",
    "primals = []\n",
    "models = []\n",
    "\n",
    "# set dual variables to zero\n",
    "#alpha = np.zeros(model.train_y.shape)\n",
    "#b = 0\n",
    "\n",
    "# begin iteration\n",
    "for t in range(max_iters):\n",
    "    passes = 0\n",
    "    while passes < max_iters:\n",
    "        num_changes = 0\n",
    "        for i in range(model.train_X.shape[0]):\n",
    "            if model.alpha[0][i] < 0 or model.alpha[0][i] > model.C or np.dot(model.alpha, model.train_y.T) != 0: \n",
    "                # Random initialize\n",
    "                j = np.random.randint(low = 0, high = model.train_X.shape[0])\n",
    "                alpha_j = model.alpha[0][j]\n",
    "\n",
    "                # Upper and Lower Bounds\n",
    "                H = min(model.C, model.C - (model.alpha[0][0] - model.alpha[0][1]))\n",
    "                L = max(0, -(model.alpha[0][0] - model.alpha[0][1]))\n",
    "\n",
    "                # Kernel Used\n",
    "                if model.kernel_func.__name__ == 'linear_kernel':\n",
    "                    K = linear_kernel(model.train_X, model.train_X)\n",
    "                elif model.kernel_func.__name__ == 'Gaussian_kernel':\n",
    "                    K = Gaussian_kernel(model.train_X, model.train_X)\n",
    "\n",
    "                #g vector with g_1 and g_2 inside for efficiency\n",
    "                g_vec = np.dot(np.multiply(model.alpha,model.train_y), K) + b\n",
    "\n",
    "                # alpha_2 value\n",
    "                alpha_new = alpha_j + ((y[0][1]*(g_vec[0][0], - y[0][0] - g_vec[0][1]+y[0][1]))\n",
    "                                        /(K[0][0] + K[1][1] - 2*K[1][2]))\n",
    "\n",
    "                # alpha_2 classification\n",
    "                if alpha_new > H:\n",
    "                    alpha_new_clipped = H\n",
    "\n",
    "                elif alpha_new < L:\n",
    "                    alpha_new_clipped = L\n",
    "\n",
    "                else: \n",
    "                    alpha_new_clipped = alpha_new\n",
    "\n",
    "                # Stopping if not meaningful change\n",
    "                if np.abs(alpha_new_clipped-alpha_j) < tol:\n",
    "\n",
    "                    continue\n",
    "\n",
    "                # Getting alpha_1 if meaningful change\n",
    "                alpha_1_new = model.alpha[0][0] + (model.train_y[0][0]*model.train_y[0][1]) * (alpha_j - alpha_new_clipped)\n",
    "\n",
    "                # b primal\n",
    "                # E vector (E_1, E_2)\n",
    "                E = g_vec - model.train_y\n",
    "                b1 = model.b - E[0][0] - model.train_y[0][0]*(alpha_1_new - model.alpha[0][0])*K[0][0] - model.train_y[0][1]*(alpha_new_clipped - alpha_j)*K[0][1]\n",
    "                b2 = model.b - E[0][1] - model.train_y[0][0]*(alpha_1_new - model.alpha[0][0])*K[0][1] - model.train_y[0][1]*(alpha_new_clipped - alpha_j)*K[1][1]\n",
    "\n",
    "                # update model values\n",
    "                # alphas\n",
    "                model.alpha[0][0] = alpha_1_new\n",
    "                model.alpha[0][1] = alpha_new_clipped\n",
    "\n",
    "                # b primal\n",
    "                if 0 < model.alpha[0][0] < model.C:\n",
    "                    b_new = b1\n",
    "                \n",
    "                elif 0 < model.alpha[0][1] < model.C:\n",
    "                    b_new = b2\n",
    "\n",
    "                else:\n",
    "                    b_new = (b1 + b2)/2\n",
    "\n",
    "                model.b = b_new\n",
    "                num_changes += 1\n",
    "        \n",
    "        if num_changes == 0:\n",
    "            passes +=1\n",
    "        else:\n",
    "            passes = 0\n",
    "    iter_num.append(t)\n",
    "    duals.append(dual_objective_function(model.alpha, model.train_y, model.train_X, model.kernel_func, model.sigma))\n",
    "    primals.append(primal_objective_function(model.alpha, model.train_y, model.train_X, model.b, model.C, model.kernel_func, model.sigma))\n",
    "    models.append(vars(model))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer = [1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem1 import*\n",
    "from problem2 import*\n",
    "\n",
    "\n",
    "\n",
    "train_X = np.array([[1, 1], [-1, -1]]).T\n",
    "train_y = np.array([[1, -1]])\n",
    "C = 10\n",
    "sigma = 1\n",
    "\n",
    "# Instantiate model\n",
    "model = SVMModel(train_X, train_y, C, linear_kernel, sigma)\n",
    "model.alpha[0, 0] = 1\n",
    "model.alpha[0, 1] = 1\n",
    "model.b = 1\n",
    "#K = np.zeros((model.train_X.shape[0]))\n",
    "#for i in range(model.train_X.shape[0]):\n",
    "    #K[i] = np.dot(np.array([model.train_X[:,i]]), model.train_X)\n",
    "#K = linear_kernel(model.train_X, model.train_X)\n",
    "vals = decision_function(model.alpha, model.train_y, model.train_X, model.b, model.kernel_func, model.sigma, model.train_X)\n",
    "assignments = np.array([1 if i > 0 else -1 for i in vals[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, -2]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array([model.train_X[:,0]]), model.train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2., -2.],\n",
       "       [-2.,  2.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([model.train_X[:,i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(model.alpha, model.train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2., -2.],\n",
       "       [-2.,  2.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_1 = model.train_X.shape\n",
    "shape_2 = model.train_X.shape\n",
    "K = np.zeros((shape_1[0], shape_2[1]))\n",
    "for i in range(shape_1[0]):\n",
    "    for j in range(shape_2[1]):\n",
    "            K[i,j] = np.dot(model.train_X[:,i], model.train_X[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 1699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 1700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2., -2.],\n",
       "       [-2.,  2.]])"
      ]
     },
     "execution_count": 1696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_1 = X1.shape\n",
    "shape_2 = X2.shape\n",
    "K = np.zeros((shape_1[0], shape_2[1]))\n",
    "if shape_1[1] == 1 and shape_2[1] == 1:\n",
    "    \n",
    "    return np.dot(X1.T, X2)\n",
    "\n",
    "else:\n",
    "    K = np.zeros((shape_1[0], shape_2[1]))\n",
    "    for i in range(shape_1[0]):\n",
    "        for j in range(shape_2[1]):\n",
    "                K[i,j] = np.dot(X1[:,i], X2[:,j])\n",
    "    rK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 1671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.alpha[0][0]*model.train_y[0][0]*K[0][0] + model.alpha[0][1]*model.train_y[0][1]*K[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.alpha[0][0]*model.train_y[0][0]*K[1][0] + model.alpha[0][1]*model.train_y[0][1]*K[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 1661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.]])"
      ]
     },
     "execution_count": 1660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(model.alpha, model.train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 1656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 1644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 1645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]"
      ]
     },
     "execution_count": 1647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0},\n",
       " {'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0},\n",
       " {'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0},\n",
       " {'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0},\n",
       " {'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0},\n",
       " {'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0},\n",
       " {'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0},\n",
       " {'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0},\n",
       " {'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0},\n",
       " {'train_X': array([[ 1, -1],\n",
       "         [ 1, -1]]),\n",
       "  'train_y': array([[ 1, -1]]),\n",
       "  'n': 2,\n",
       "  'm': 2,\n",
       "  'C': 10,\n",
       "  'kernel_func': <function problem1.linear_kernel(X1, X2)>,\n",
       "  'sigma': 1,\n",
       "  'alpha': array([[0., 0.]]),\n",
       "  'b': 0}]"
      ]
     },
     "execution_count": 1648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = linear_kernel(model.train_X, model.train_X)\n",
    "g_vec = np.dot(np.multiply(model.alpha,model.train_y), K) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1]])"
      ]
     },
     "execution_count": 1641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.]])"
      ]
     },
     "execution_count": 1642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_vec - model.train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 1630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(alpha, model.train_y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.]])"
      ]
     },
     "execution_count": 1626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1]])"
      ]
     },
     "execution_count": 1628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhh = model.train_X.shape[0]\n",
    "\n",
    "samp_idx = np.random.randint(low = 0, high = model.train_X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2)"
      ]
     },
     "execution_count": 1608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "blob = pd.read_pickle(r'C:\\MFE\\MFE Sem 3\\CSE 426\\CSE_426\\Project 2\\data\\blobs_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob['tr_X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array([[1, 2], [2, 4]]).T\n",
    "X2 = np.array([[3, 4], [1, 2], [5, 6]]).T\n",
    "sigma = 5\n",
    "np.exp(-(euclidean_distances(X1,X2)**2)/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85214379, 0.98019867],\n",
       "       [1.        , 0.90483742],\n",
       "       [0.52729242, 0.77105159]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.array([[1, 2], [2, 4]]).T\n",
    "X1 = np.array([[3, 4], [1, 2], [5, 6]]).T\n",
    "sigma = 5\n",
    "np.exp(-(euclidean_distances(X1,X2.T)**2)/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array([[1, 1], [-1, -1]]).T\n",
    "train_y = np.array([[1, -1]])\n",
    "alpha = np.array([[1, 1]])\n",
    "b = -1\n",
    "C = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = linear_kernel(train_X, train_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(alpha, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ||w||^2 \n",
    "front = np.dot(np.dot(np.multiply(alpha, train_y), K), np.multiply(alpha, train_y).T) \n",
    "# y(wTx+b)\n",
    "z = sum(np.dot(np.multiply(alpha,train_y),K))+b\n",
    "# loss\n",
    "loss = hinge_loss(z, train_y)\n",
    "\n",
    "Lin = 0.5*front + C*np.sum(loss)\n",
    "\n",
    "Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  5, 17],\n",
       "       [22, 10, 34]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X1.T, X2) # linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array([[1, 2]]).T\n",
    "X2 = np.array([[3, 4]]).T\n",
    "sigma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01831564]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-(euclidean_distances(X1.T,X2.T)**2)/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-(euclidean_distances(np.array([X1]),np.array([X2]))**2)/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Problem 4: Train an SVM using SMO, on 3 simulated datasets (blobs, circles, and two moons) with 2 kernels (Linear and Gaussian)\n",
    "'''\n",
    "\n",
    "from problem1 import *\n",
    "from problem2 import *\n",
    "from problem3 import *\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_circles, make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def generate_dataset(n_samples, distribution_name):\n",
    "    if distribution_name == 'blobs':\n",
    "        X_train, y = make_blobs(n_samples, centers=2, n_features=2, random_state=1)\n",
    "    elif distribution_name == 'circles':\n",
    "        X_train, y = make_circles(n_samples, noise=0.01, factor=0.1, random_state=1)\n",
    "    else:\n",
    "        X_train, y = make_moons(n_samples, noise=0.01, random_state=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train, y)\n",
    "    X_train_scaled = X_train_scaled.T\n",
    "    y[y == 0] = -1\n",
    "    print('y.shape', y.shape)\n",
    "    return X_train_scaled, np.expand_dims(y, axis=0)\n",
    "\n",
    "\n",
    "def train_test_SVM(**kwargs):\n",
    "    \"\"\"\n",
    "    Don't change this function.\n",
    "    :param kwargs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Instantiate a SVM model\n",
    "    model = SVMModel(kwargs['Training X'],\n",
    "                     kwargs['Training y'],\n",
    "                     kwargs['C'],\n",
    "                     kwargs['kernel'],\n",
    "                     kwargs['sigma'])\n",
    "\n",
    "    # call the train function from problem3.\n",
    "    iter_num, duals, primals, models = train(model, kwargs['max_iters'], kwargs['record_every'])\n",
    "\n",
    "    for it, d, p in zip(iter_num, duals, primals):\n",
    "        print('iterations = {}: dual objective value = {}, primal objective value = {}'.format(it, d, p))\n",
    "\n",
    "    # save your trained model to file\n",
    "    with open('C:/MFE/MFE Sem 3/CSE 426/CSE_426/Project 2/data/trained_model_{}_{}.pkl'.format(kwargs['distribution'], kwargs['kernel'].__name__), 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    # call the predict function from problem3.\n",
    "    predicted_y = predict(model, kwargs['Test X'])\n",
    "\n",
    "    print('Test accuracy = {}'.format(accuracy_score(np.array(kwargs['Test y']).flatten(), np.array(predicted_y).flatten())))\n",
    "\n",
    "# --------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========Data distribution = blobs========\n",
      "========using kernel linear_kernel========\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,100) and (2,100) not aligned: 100 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\MFE\\MFE Sem 3\\CSE 426\\CSE_426\\Project 2\\src\\scratch.ipynb Cell 97\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m========using kernel \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m========\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(kernel\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdistribution\u001b[39m\u001b[39m'\u001b[39m: dist,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mTraining X\u001b[39m\u001b[39m'\u001b[39m: tr_X,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mTraining y\u001b[39m\u001b[39m'\u001b[39m: tr_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mrecord_every\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m           }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m train_test_SVM(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\MFE\\MFE Sem 3\\CSE 426\\CSE_426\\Project 2\\src\\scratch.ipynb Cell 97\u001b[0m in \u001b[0;36mtrain_test_SVM\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model \u001b[39m=\u001b[39m SVMModel(kwargs[\u001b[39m'\u001b[39m\u001b[39mTraining X\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                  kwargs[\u001b[39m'\u001b[39m\u001b[39mTraining y\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                  kwargs[\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                  kwargs[\u001b[39m'\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                  kwargs[\u001b[39m'\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# call the train function from problem3.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m iter_num, duals, primals, models \u001b[39m=\u001b[39m train(model, kwargs[\u001b[39m'\u001b[39;49m\u001b[39mmax_iters\u001b[39;49m\u001b[39m'\u001b[39;49m], kwargs[\u001b[39m'\u001b[39;49m\u001b[39mrecord_every\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m it, d, p \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(iter_num, duals, primals):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MFE/MFE%20Sem%203/CSE%20426/CSE_426/Project%202/src/scratch.ipynb#Z1236sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39miterations = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: dual objective value = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, primal objective value = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(it, d, p))\n",
      "File \u001b[1;32mc:\\MFE\\MFE Sem 3\\CSE 426\\CSE_426\\Project 2\\src\\problem3.py:140\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, max_iters, record_every, max_passes, tol)\u001b[0m\n\u001b[0;32m    138\u001b[0m     iter_num\u001b[39m.\u001b[39mappend(t)\n\u001b[0;32m    139\u001b[0m     duals\u001b[39m.\u001b[39mappend(dual_objective_function(model\u001b[39m.\u001b[39malpha, model\u001b[39m.\u001b[39mtrain_y, model\u001b[39m.\u001b[39mtrain_X, model\u001b[39m.\u001b[39mkernel_func, model\u001b[39m.\u001b[39msigma))\n\u001b[1;32m--> 140\u001b[0m     primals\u001b[39m.\u001b[39mappend(primal_objective_function(model\u001b[39m.\u001b[39;49malpha, model\u001b[39m.\u001b[39;49mtrain_y, model\u001b[39m.\u001b[39;49mtrain_X, model\u001b[39m.\u001b[39;49mb, model\u001b[39m.\u001b[39;49mC, model\u001b[39m.\u001b[39;49mkernel_func, model\u001b[39m.\u001b[39;49msigma))\n\u001b[0;32m    141\u001b[0m     models\u001b[39m.\u001b[39mappend(\u001b[39mvars\u001b[39m(model))\n\u001b[0;32m    142\u001b[0m \u001b[39melif\u001b[39;00m t \u001b[39m-\u001b[39m iter_num[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m record_every:\n",
      "File \u001b[1;32mc:\\MFE\\MFE Sem 3\\CSE 426\\CSE_426\\Project 2\\src\\problem2.py:72\u001b[0m, in \u001b[0;36mprimal_objective_function\u001b[1;34m(alpha, train_y, train_X, b, C, kernel_function, sigma)\u001b[0m\n\u001b[0;32m     69\u001b[0m K \u001b[39m=\u001b[39m linear_kernel(train_X, train_X)\n\u001b[0;32m     71\u001b[0m \u001b[39m# ||w||^2 \u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m front \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39;49mdot(np\u001b[39m.\u001b[39;49mmultiply(alpha, train_y), K), np\u001b[39m.\u001b[39mmultiply(alpha, train_y)) \n\u001b[0;32m     73\u001b[0m \u001b[39m# y(wTx+b)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m z \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mmultiply(alpha,train_y),K))\u001b[39m+\u001b[39mb\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,100) and (2,100) not aligned: 100 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    C = 1.0\n",
    "    sigma = 0.1\n",
    "\n",
    "    n_samples = 100\n",
    "    for dist in ['blobs', 'circles', 'moons']:\n",
    "        print ('\\n\\n========Data distribution = {}========'.format(dist))\n",
    "        tr_X, tr_y = generate_dataset(n_samples, dist)\n",
    "        te_X, te_y = generate_dataset(n_samples, dist)\n",
    "        \n",
    "        with open('C:/MFE/MFE Sem 3/CSE 426/CSE_426/Project 2/data/' + dist + '_data.pkl', 'wb') as f:\n",
    "             pickle.dump({'tr_X':tr_X,\n",
    "                          'tr_y':tr_y,\n",
    "                          'te_X':te_X,\n",
    "                          'te_y':te_y}, f)\n",
    "        with open('C:/MFE/MFE Sem 3/CSE 426/CSE_426/Project 2/data/' + dist + '_data.pkl', 'rb') as f:\n",
    "            data_dict = pickle.load(f)\n",
    "        tr_X = data_dict['tr_X']\n",
    "        tr_y = data_dict['tr_y']\n",
    "        te_X = data_dict['te_X']\n",
    "        te_y = data_dict['te_y']\n",
    "\n",
    "        for kernel in [linear_kernel, Gaussian_kernel]:\n",
    "        # for kernel in [Gaussian_kernel]:\n",
    "\n",
    "            print ('========using kernel {}========'.format(kernel.__name__))\n",
    "            kwargs = {'distribution': dist,\n",
    "                      'Training X': tr_X,\n",
    "                      'Training y': tr_y,\n",
    "                      'Test X': te_X,\n",
    "                      'Test y': te_y,\n",
    "                      'C': C,\n",
    "                      'sigma': sigma,\n",
    "                      'kernel': kernel,\n",
    "                      'max_iters': 10,\n",
    "                      'record_every': 1\n",
    "                      }\n",
    "\n",
    "            train_test_SVM(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "blob = pd.read_pickle(r'C:\\MFE\\MFE Sem 3\\CSE 426\\CSE_426\\Project 2\\data\\blobs_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tr_X', 'tr_y', 'te_X', 'te_y'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y = make_blobs(n_samples, centers=2, n_features=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVMModel(blob['tr_X'], blob['tr_y'], 1, linear_kernel, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = linear_kernel(np.array([model.train_X.T[:,0]]), np.array([model.train_X.T[:,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_vec = np.dot(np.multiply(model.alpha,model.train_y), K.T) + model.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 10\n",
    "record_every = 1\n",
    "max_passes = 1\n",
    "tol=1e-6\n",
    "\n",
    "iter_num = []\n",
    "duals = []\n",
    "primals = []\n",
    "models = []\n",
    "\n",
    "# set dual variables to zero\n",
    "#alpha = np.zeros(model.train_y.shape)\n",
    "#b = 0\n",
    "\n",
    "# begin iteration\n",
    "for t in range(max_iters):\n",
    "    passes = 0\n",
    "    while passes < max_passes:\n",
    "        num_changes = 0\n",
    "        for i in range(model.m):\n",
    "            if model.alpha[0][i] < 0 or model.alpha[0][i] > model.C or np.dot(model.alpha, model.train_y.T) != 0 or : \n",
    "                # Random initialize\n",
    "                j = np.random.randint(low = 0, high = model.m)\n",
    "                alpha_j = model.alpha[0][j]\n",
    "\n",
    "                # Upper and Lower Bounds\n",
    "                H = min(model.C, model.C - (model.alpha[0][i] - model.alpha[0][j]))\n",
    "                L = max(0, -(model.alpha[0][i] - model.alpha[0][j]))\n",
    "\n",
    "                # Kernel Used\n",
    "                if model.kernel_func.__name__ == 'linear_kernel':\n",
    "                    K = linear_kernel(model.train_X, model.train_X)\n",
    "                elif model.kernel_func.__name__ == 'Gaussian_kernel':\n",
    "                    K = Gaussian_kernel(model.train_X, model.train_X)\n",
    "                print(K)\n",
    "                #g vector with g_1 and g_2 inside for efficiency\n",
    "                g_vec = np.dot(np.multiply(model.alpha,model.train_y), K) + model.b\n",
    "\n",
    "                # alpha_2 value\n",
    "                alpha_new = alpha_j + ((model.train_y[0][i]*(g_vec[0][0], - model.train_y[0][i] - g_vec[0][1] + model.train_y[0][j]))\n",
    "                                        /(K[0][0] + K[1][1] - 2*K[0][2]))\n",
    "\n",
    "                # alpha_2 classification\n",
    "                if alpha_new > H:\n",
    "                    alpha_new_clipped = H\n",
    "\n",
    "                elif alpha_new < L:\n",
    "                    alpha_new_clipped = L\n",
    "\n",
    "                else: \n",
    "                    alpha_new_clipped = alpha_new\n",
    "\n",
    "                # Stopping if not meaningful change\n",
    "                if np.abs(alpha_new_clipped-alpha_j) < tol:\n",
    "\n",
    "                    continue\n",
    "\n",
    "                # Getting alpha_1 if meaningful change\n",
    "                alpha_1_new = model.alpha[0][0] + (model.train_y[0][0]*model.train_y[0][1]) * (alpha_j - alpha_new_clipped)\n",
    "\n",
    "                # b primal\n",
    "                # E vector (E_1, E_2)\n",
    "                E = g_vec - model.train_y\n",
    "                b1 = model.b - E[0][0] - model.train_y[0][0]*(alpha_1_new - model.alpha[0][0])*K[0][0] - model.train_y[0][1]*(alpha_new_clipped - alpha_j)*K[0][1]\n",
    "                b2 = model.b - E[0][1] - model.train_y[0][0]*(alpha_1_new - model.alpha[0][0])*K[0][1] - model.train_y[0][1]*(alpha_new_clipped - alpha_j)*K[1][1]\n",
    "\n",
    "                # update model values\n",
    "                # alphas\n",
    "                model.alpha[0][0] = alpha_1_new\n",
    "                model.alpha[0][1] = alpha_new_clipped\n",
    "\n",
    "                # b primal\n",
    "                if 0 < model.alpha[0][0] < model.C:\n",
    "                    b_new = b1\n",
    "                \n",
    "                elif 0 < model.alpha[0][1] < model.C:\n",
    "                    b_new = b2\n",
    "\n",
    "                else:\n",
    "                    b_new = (b1 + b2)/2\n",
    "\n",
    "                model.b = b_new\n",
    "                num_changes += 1\n",
    "        \n",
    "        if num_changes == 0:\n",
    "            passes +=1\n",
    "        else:\n",
    "            passes = 0\n",
    "    if t == 0:\n",
    "        iter_num.append(t)\n",
    "        duals.append(dual_objective_function(model.alpha, model.train_y, model.train_X, model.kernel_func, model.sigma))\n",
    "        primals.append(primal_objective_function(model.alpha, model.train_y, model.train_X, model.b, model.C, model.kernel_func, model.sigma))\n",
    "        models.append(vars(model))\n",
    "    elif t - iter_num[-1] == record_every:\n",
    "        iter_num.append(t)\n",
    "        duals.append(dual_objective_function(model.alpha, model.train_y, model.train_X, model.kernel_func, model.sigma))\n",
    "        primals.append(primal_objective_function(model.alpha, model.train_y, model.train_X, model.b, model.C, model.kernel_func, model.sigma))\n",
    "        models.append(vars(model))\n",
    "#return iter_num, duals, primals, models\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8377259de029fbe3469e5825885a3984679ef58677fe54558bfe80e0473ceee4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
